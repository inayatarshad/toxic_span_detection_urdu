ğŸ” Multimodal Urdu Toxic Span Detection
A multimodal framework for detecting toxic content in Urdu text and audio, combining XLM-RoBERTa for text-based toxic span detection with Wav2Vec2 for audio-based toxicity classification via late fusion.

ğŸ“Œ Overview
This project extends MUTEX (Multilingual Transformer + CRF for Urdu Toxic Span Detection) by adding an audio modality, creating the first multimodal pipeline for Urdu toxic content detection.
| Modality | Model | F1 Score |
|---|---|---|
| Text only | XLM-RoBERTa | 67% |
| Audio only | Wav2Vec2 | 70% |
| **Multimodal Fusion** | **XLM-RoBERTa + Wav2Vec2** | **79.34%** |

## ğŸ—‚ï¸ Project Structure
```
ğŸ“ Project
â”‚
â”œâ”€â”€ ğŸ““ Notebook 1 â€” Text Model (MUTEX)
â”‚   â””â”€â”€ XLM-RoBERTa fine-tuned on URTOX for toxic span detection
â”‚
â”œâ”€â”€ ğŸ““ Notebook 2 â€” Audio Model
â”‚   â”œâ”€â”€ TTS audio generation from URTOX using Edge TTS
â”‚   â”œâ”€â”€ Wav2Vec2 feature extraction
â”‚   â””â”€â”€ Audio toxic classifier training
â”‚
â”œâ”€â”€ ğŸ““ Notebook 3 â€” Fusion
â”‚   â”œâ”€â”€ Late fusion (0.6 text + 0.4 audio)
â”‚   â”œâ”€â”€ Final multimodal evaluation
â”‚   â””â”€â”€ Real-world WhatsApp audio testing pipeline
â”‚
â””â”€â”€ ğŸ“ Dataset
    â”œâ”€â”€ URTOX_v2.csv                    â† Original text dataset (14,342 samples)
    â”œâ”€â”€ urdu_toxic_audio_dataset.csv    â† Dataset with audio paths
    â””â”€â”€ urdu_toxic_audio_og/            â† MP3 audio files folder
```

ğŸ“Š Dataset â€” URTOX
URTOX is a manually annotated Urdu toxic span dataset containing 14,342 samples collected from:

| Source | Samples | Toxic % | Non-Toxic % |
|---|---|---|---|
| Social Media (X, Instagram, Reddit) | 5,254 | 57% | 43% |
| Urdu Newspapers | 4,300 | 52% | 48% |
| YouTube | 4,788 | 56% | 44% |
| **Total** | **14,342** | **54%** | **46%** |

**Dataset Columns
id            â†’ unique identifier
text          â†’ raw Urdu text
tokens        â†’ tokenized words (list)
BIO_tags      â†’ token-level BIO annotation (B-Toxic, I-Toxic, O)
toxic_spans   â†’ toxic word spans
toxic_list    â†’ list of toxic words
label         â†’ sentence-level label (toxic / non_toxic)
sub_label     â†’ toxicity category (hate, insult, offensive, neutral)
audio_path    â†’ path to corresponding MP3 file


<img width="1105" height="272" alt="image" src="https://github.com/user-attachments/assets/cf15574c-d65c-4adb-9af1-37cd694e243d" />

<img width="1080" height="332" alt="image" src="https://github.com/user-attachments/assets/dccf1ca4-de1f-4b92-8550-4e983601b35d" />

          
## ğŸ“ About

This project focuses on toxic span detection in Urdu text using a 
transformer-based token classification approach. The goal is not only 
to identify whether a sentence contains toxic content, but also to 
**locate and highlight the specific toxic words or spans** within the text.

**No prior work exists on Urdu toxic span detection** â€” this is the 
first proposed framework for fine-grained toxicity localization in Urdu.

> ğŸ“„ A journal paper has been submitted to **Elsevier Applied Soft Computing** 
> and will be published soon.

### ğŸ¯ Task Summary

| Component | Details |
|---|---|
| Task | Toxic span detection at word/token level in Urdu |
| Model | XLM-RoBERTa fine-tuned for token classification |
| Dataset | Newly created and manually annotated Urdu toxic span dataset |
| Output | Highlighted toxic words/spans within each input sentence |
| Use Case | Moderation, abusive language detection, explainable toxicity analysis |
| Framework | HuggingFace Transformers + PyTorch |
